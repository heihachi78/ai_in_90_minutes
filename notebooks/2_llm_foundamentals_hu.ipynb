{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "few shot examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM - Large Language Models avagy Nagy Nyelvi Modellek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mik azok a (Nagy) Nyelvi Modellek?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Egy LM (Language Model) a bemenet alapján előrejelzi a következő szót.\n",
    "\n",
    "Input: Ma szépen süt a\n",
    "\n",
    "Output: nap\n",
    "\n",
    "Attól függően, hogy milyen volt a tanításhoz használt __corpus__ a következő szó előrejelzés jelentősen eltérhet. A következő szó előrejelzése valószínűség alapján történik: melyik a legvalószínűbb következő szó. Ez a valószínűség nyilván attól fogg függni, hogy mit látott korábban a modell, mit tanult meg. Ezért fontos a __corpus__.\n",
    "\n",
    "Mivel csak valószínűségeknek van szerepe, ezért lehet, hogy a legvalószínűbb predikció nincs kapcsolatban a valósággal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezek ugyan olyan neurális hálózatok, mint amilyeneket korábban láttunk, a különbség azokhoz képest (mint ahogy az már sejthető is) leginkább a tanításuk módjában rejlik. A tanításuk általában több lépésben történik:\n",
    "- pre-training: a corpus alapján megtanítják a modellnek a következő token előrejelzését\n",
    "- supervised fine tuning:\n",
    "  - ez előtanított modellnek megtanítják, hogyan kövessen utasításokat, ezáltal könnyebbé teszik a használatát\n",
    "  - egy olyan előre összeállított adathalmaz, amiben megvan a user által feltett kérdés és megvan az elvárt válasz\n",
    "- reinforcement learning with human feedback:\n",
    "  -  finomhangolják a modellt, hogy jobban kövesse az emberi értékrendet, emberi gondolkodást"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nagy nyelvi modellek (LLM) felépítése több rétegű neurális hálózatokból áll. Ezek a rétegek közé tartoznak a embedding rétegek, a recurrent rétegek, a feedforward rétegek és a attention rétegek.\n",
    "\n",
    "A beágyazó (embedding) réteg a bemeneti szöveg minden egyes szavát nagydimenziós vektorreprezentációvá alakítja. Ez a reprezentáció szemantikai és szintaktikai információkat rögzít a szóról, ami segít a modellnek megérteni a kontextust.\n",
    "\n",
    "A feedforward rétegek nemlineáris transzformációkat alkalmaznak a bemeneti beágyazásokra. Ez segít a modellnek magasabb szintű absztrakciókat tanulni a bemeneti szövegből.\n",
    "\n",
    "A rekurrens rétegek sorban értelmezik a bemeneti szövegből származó információkat. Fenntartanak egy rejtett állapotot, amely minden egyes következő szónál frissül, így a modell képes megragadni a mondatban lévő szavak közötti függőségeket.\n",
    "\n",
    "A figyelem (attention) mechanizmus lehetővé teszi, hogy a modell szelektíven a bemeneti szöveg különböző részeire összpontosítson. Ez segít a modellnek a bemeneti szöveg leglényegesebb részeire figyelni, és pontosabb előrejelzéseket generálni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM használata Azure OpenAI-val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Kérés/válasz minta**: Hasonló a REST API-khoz\n",
    "- **Üzenetek**: Beszélgetési kontextus (system, user, assistant szerepek)\n",
    "- **Model paraméter**: Meghatározza, melyik LLM-et használjuk\n",
    "- **Temperature és egyéb paraméterek**: Viselkedés szabályozása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_API_BASE\")\n",
    "model_name = os.getenv(\"AZURE_API_MODEL\")\n",
    "deployment = os.getenv(\"AZURE_API_MODEL\")\n",
    "\n",
    "subscription_key = os.getenv(\"AZURE_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase \"the meaning of life\" is subjective and philosophical, not strictly quantifiable. If you mean \"half of the number associated with life’s meaning,\" some popular culture references 42 as the meaning of life (from *The Hitchhiker's Guide to the Galaxy*), so half would be 21. Otherwise, the \"meaning of life\" doesn't have a numerical value to halve.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a professor of data science and artificial intelligence, and you need to answer questions from your students. You need to be very precise with your answers, but at the same time try to be short.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the half of the meaning of life?\",\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=800,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"azure/\"+os.getenv(\"AZURE_API_MODEL\"), temperature=0.1, max_tokens=768)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data streams converge,  Python scripts parse, transform, flow—  dspy crafts insights.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Write a haiku about dspy, but be technical?\")[0].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mik azok a Tokenek?**\n",
    "\n",
    "- A szöveg **\"tokenekre\"** bontva (gyakran részszavak, nem teljes szavak)\n",
    "- Az LLM-ek a tokeneket számokként dolgozzák fel (nem szövegként)\n",
    "- A tokenizáció hatással van a **költségre**, **kontextus méretre** és **viselkedésre**\n",
    "  - általában tokenek alapján számláznak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([24912, 2375], [24912, 2375, 2418])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "enc.encode(\"hello world\"), enc.encode(\"hello world again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15339, 1917], [15339, 1917, 1578])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "enc.encode(\"hello world\"), enc.encode(\"hello world again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eredeti szöveg: Kedves Mikulás! Azért írok neked, hogy elmondjam milyen ajándékokat kérek.\n",
      "Tokenek száma: 26\n",
      "Tokenek: [42, 295, 3350, 41369, 361, 2294, 0, 13417, 46812, 5471, 17690, 21723, 295, 11, 19891, 650, 17895, 24395, 195394, 7261, 20091, 27991, 52539, 61690, 16532, 13]\n",
      "Egyedi tokenek:\n",
      "  Token 0: 42 → 'K'\n",
      "  Token 1: 295 → 'ed'\n",
      "  Token 2: 3350 → 'ves'\n",
      "  Token 3: 41369 → ' Mik'\n",
      "  Token 4: 361 → 'ul'\n",
      "  Token 5: 2294 → 'ás'\n",
      "  Token 6: 0 → '!'\n",
      "  Token 7: 13417 → ' Az'\n",
      "  Token 8: 46812 → 'ért'\n",
      "  Token 9: 5471 → ' í'\n",
      "  ... és még 16 token\n",
      "Eredeti szöveg: Knowledge is knowing that a tomato is a fruit, wisdom is knowing not to put in a fruit salad.\n",
      "Tokenek száma: 21\n",
      "Tokenek: [87447, 382, 19578, 484, 261, 59604, 382, 261, 15310, 11, 32646, 382, 19578, 625, 316, 3006, 306, 261, 15310, 38312, 13]\n",
      "Egyedi tokenek:\n",
      "  Token 0: 87447 → 'Knowledge'\n",
      "  Token 1: 382 → ' is'\n",
      "  Token 2: 19578 → ' knowing'\n",
      "  Token 3: 484 → ' that'\n",
      "  Token 4: 261 → ' a'\n",
      "  Token 5: 59604 → ' tomato'\n",
      "  Token 6: 382 → ' is'\n",
      "  Token 7: 261 → ' a'\n",
      "  Token 8: 15310 → ' fruit'\n",
      "  Token 9: 11 → ','\n",
      "  ... és még 11 token\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "texts = [\n",
    "    \"Kedves Mikulás! Azért írok neked, hogy elmondjam milyen ajándékokat kérek.\",\n",
    "    \"Knowledge is knowing that a tomato is a fruit, wisdom is knowing not to put in a fruit salad.\",\n",
    "]\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "for text in texts:\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"Eredeti szöveg: {text}\")\n",
    "    print(f\"Tokenek száma: {len(tokens)}\")\n",
    "    print(f\"Tokenek: {tokens}\")\n",
    "    \n",
    "    print(\"Egyedi tokenek:\")\n",
    "    for i, token in enumerate(tokens[:10]):  # Első 10 token megjelenítése\n",
    "        decoded = encoding.decode([token])\n",
    "        print(f\"  Token {i}: {token} → '{decoded}'\")\n",
    "    if len(tokens) > 10:\n",
    "        print(f\"  ... és még {len(tokens) - 10} token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Tokenizer Web: https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "kov_token_probak = {\"Párizs\": 0.85, \"Lyon\": 0.05, \"található\": 0.03, \"nevezik\": 0.02, \"ismeretlen\": 0.01, \"egyéb\": 0.04}\n",
    "plt.bar(kov_token_probak.keys(), kov_token_probak.values())\n",
    "plt.title(\"Valószínűségek a következő tokenre: 'Franciaország fővárosa ...'\")\n",
    "plt.ylabel(\"Valószínűség\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def teszt_temperature(client):\n",
    "    prompt = \"Irj egy vidám történetet egy kisegérről. Maximum 3 mondat legyen.\"\n",
    "    for temp in [0.1, 0.7, 1.2]:\n",
    "        time.sleep(0.2)\n",
    "        print(f\"\\n--- Hőmérséklet {temp} ---\")\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temp,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            print(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"API hiba: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hőmérséklet 0.1 ---\n",
      "Egy kis egérke, Pipike, egyszer véletlenül belebújt egy hatalmas sajtdobozba, amit a gazdi a konyhapultra tett. Amikor felébredt, körülötte minden sajtdarab táncolt, mintha egy vidám buli közepén lenne. Pipike nevetve döntött úgy, hogy ezentúl minden nap egy sajtbuli lesz az ő kis világában!\n",
      "\n",
      "--- Hőmérséklet 0.7 ---\n",
      "Egy kis egér, aki mindig kalandvágyó volt, egyszer titokban bejutott a nagyi konyhájába, és megevett egy hatalmas sajtdarabkát. Amikor a nagyi észrevette, csak nevetett, mert a kis egér olyan aranyos volt, hogy nem haragudott rá. Azóta minden este közösen meséltek és nevettek a kandalló mellett.\n",
      "\n",
      "--- Hőmérséklet 1.2 ---\n",
      "Egy kis egér, akit Mikkinek hívtak, mindig elbújt a könyvespolc között, mert ott érezte magát a legbiztonságosabban. Egy nap azonban rátalált egy apró zseblámpára, amivel felfedezte a szoba minden titkos zugát, és innentől kezdve boldogan kalandozott, mint egy indaindulásos kis felfedező. A\n"
     ]
    }
   ],
   "source": [
    "teszt_temperature(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A temperature működése\n",
    "\n",
    "- Alapfolyamat: Az LLM először kiszámítja minden lehetséges token \"nyers pontszámát\" (logits)\n",
    "- Temperature alkalmazása: Ezeket a pontszámokat elosztja a temperature értékével\n",
    "- Softmax: Az eredményen softmax függvényt alkalmaz, ami valószínűség-eloszlást ad\n",
    "\n",
    "\n",
    "Temperature = 0.1 (alacsony):\n",
    "\n",
    "- A legnagyobb pontszámú tokenek még nagyobb valószínűséget kapnak\n",
    "- Determinisztikusabb, kiszámíthatóbb válaszok\n",
    "\n",
    "\n",
    "Temperature = 1.0 (semleges):\n",
    "\n",
    "- Az eredeti valószínűség-eloszlás változatlan\n",
    "\n",
    "\n",
    "Temperature = 2.0 (magas):\n",
    "\n",
    "- A valószínűségek \"kiegyenlítődnek\"\n",
    "- Kevésbé valószínű tokenek is nagyobb esélyt kapnak\n",
    "\n",
    "\n",
    "\n",
    "**Példa**\n",
    "\n",
    "Ha az eredeti logitok: [4.0, 3.0, 2.0] token-ekre:\n",
    "\n",
    "- Temperature 0.5-nél: ~[0.85, 0.12, 0.03] valószínűségek\n",
    "- Temperature 1.0-nél: ~[0.67, 0.24, 0.09] valószínűségek\n",
    "- Temperature 2.0-nél: ~[0.46, 0.31, 0.23] valószínűségek\n",
    "\n",
    "Tehát a temperature megváltoztatja a következő token kiválasztásának valószínűség-eloszlását."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezt minden egyes modell családnál érdemes figyelembe venni: https://cookbook.openai.com/examples/gpt4-1_prompting_guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      " Írj kódot\n",
      "--------------------------------------------------------------------------------\n",
      "Persze! Mit szeretnél, hogy írjak? Milyen nyelven és milyen feladatra? \n",
      "\n",
      "================================================================================\n",
      "\n",
      " Írj egy Python függvényt, amely kiszámolja egy szám faktoriálisát\n",
      "--------------------------------------------------------------------------------\n",
      "Természetesen! Íme egy egyszerű Python függvény, amely kiszámolja egy szám faktoriálisát:\n",
      "\n",
      "```python\n",
      "def faktorialis(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"A faktoriális csak nem negatív egész számokra értelmezett.\")\n",
      "    eredmeny = 1\n",
      "    for i in range(2, n + 1):\n",
      "        eredmeny *= i\n",
      "    return eredmeny\n",
      "\n",
      "# Példa használat:\n",
      "print(faktorialis(5))  # Eredmény: 120\n",
      "```\n",
      "\n",
      "Ha szeretnéd, rekurzív megoldást is tudok mutatni! \n",
      "\n",
      "================================================================================\n",
      "\n",
      " Írj egy Python függvényt, amely:  1. Pozitív egész szám faktoriálisát számolja  2. Hibakezelést tartalmaz  3. Dokumentált példákkal  4. Rekurzív\n",
      "--------------------------------------------------------------------------------\n",
      "Természetesen! Íme egy Python függvény, amely rekurzívan számolja ki egy pozitív egész szám faktoriálisát, tartalmaz hibakezelést, és dokumentált példákkal is ellátott:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    \"\"\"\n",
      "    Számolja ki egy pozitív egész szám faktoriálisát rekurzívan.\n",
      "    \n",
      "    Paraméterek:\n",
      "    n (int): A szám, amelynek a faktoriálisát szeretnénk kiszámolni. Csak pozitív egész szám lehet.\n",
      "    \n",
      "    Visszatérési érték:\n",
      "    int: n faktoriálisa.\n",
      "    \n",
      "    Kivételek:\n",
      "    ValueError: Ha n nem pozitív egész szám.\n",
      "    \n",
      "    Példák:\n",
      "    >>> factorial(1)\n",
      "    1\n",
      "    >>> factorial(5)\n",
      "    120\n",
      "    >>> factorial(0)\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: Csak pozitív egész szám faktoriálisát lehet számolni.\n",
      "    >>> factorial(-3)\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: Csak pozitív egész szám faktoriálisát lehet számolni.\n",
      "    >>> factorial(3.5)\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: Csak pozitív egész szám faktoriálisát lehet számolni.\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int) or n <= 0:\n",
      "        raise ValueError(\"Csak pozitív egész szám faktoriálisát lehet számolni.\")\n",
      "    if n == 1:\n",
      "        return 1\n",
      "    return n * factorial(n - 1)\n",
      "```\n",
      "\n",
      "Ez a függvény ellenőrzi, hogy a bemenet pozitív egész szám-e, különben `ValueError`-t dob. A rekurzió a megszokott módon működik: `factorial(n) = n * factorial(n-1)`, ahol a megszorítás az, hogy `factorial(1) = 1`. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "promtok = [\n",
    "\"Írj kódot\",\n",
    "\"Írj egy Python függvényt, amely kiszámolja egy szám faktoriálisát\",\n",
    "\"Írj egy Python függvényt, amely: \\\n",
    " 1. Pozitív egész szám faktoriálisát számolja \\\n",
    " 2. Hibakezelést tartalmaz \\\n",
    " 3. Dokumentált példákkal \\\n",
    " 4. Rekurzív\"\n",
    "]\n",
    "for i, prompt in enumerate(promtok):\n",
    "    print('='*80)\n",
    "    print('\\n', prompt)\n",
    "    print('-'*80)\n",
    "    time.sleep(0.2)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=1.0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        print(response.choices[0].message.content, '\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"API hiba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One, Few, Many-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few-shot learning az egyik leghatékonyabb prompt engineering technika, ami arra épül, hogy az LLM-ek kiválóan tudnak tanulni példákból a kontextusban. Ahelyett, hogy csak leírnád mit szeretnél, mutatsz néhány konkrét példát a kívánt formátumra/stílusra, az LLM ezt a mintát fogja követni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-shot: 1 példa\n",
    "- Few-shot: 2-5 példa (általában 3 az optimális)\n",
    "- Many-shot: 5+ példa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(task_description, examples, new_input):\n",
    "    prompt = f\"{task_description}\\n\\nPéldák:\\n\"\n",
    "    \n",
    "    for example in examples:\n",
    "        prompt += f\"Input: {example['input']}\\n\"\n",
    "        prompt += f\"Output: {example['output']}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Most ezt dolgozd fel:\\nInput: {new_input}\\nOutput:\"\n",
    "    return prompt\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"def factorial(n):\", \"output\": \"Faktoriális számítás függvény\"},\n",
    "    {\"input\": \"class Car:\", \"output\": \"Autó osztály definíció\"},\n",
    "    {\"input\": \"import pandas\", \"output\": \"Pandas könyvtár importálás\"}\n",
    "]\n",
    "\n",
    "prompt = create_few_shot_prompt(\n",
    "    \"Írj rövid, magyar nyelvű leírást Python kód részletekről\",\n",
    "    examples,\n",
    "    \"for i in range(10):\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Írj rövid, magyar nyelvű leírást Python kód részletekről\n",
      "\n",
      "Példák:\n",
      "Input: def factorial(n):\n",
      "Output: Faktoriális számítás függvény\n",
      "\n",
      "Input: class Car:\n",
      "Output: Autó osztály definíció\n",
      "\n",
      "Input: import pandas\n",
      "Output: Pandas könyvtár importálás\n",
      "\n",
      "Most ezt dolgozd fel:\n",
      "Input: for i in range(10):\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ciklus, amely 0-tól 9-ig iterál.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciklus, amely 0-tól 9-ig iterál. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=1.0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "print(response.choices[0].message.content, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of Tought (CoT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Chain of Thought (CoT) egy prompt engineering technika, ami arra tanítja az LLM-et, hogy lépésről lépésre, strukturáltan gondolkodjon a válasz megadása előtt.\n",
    "\n",
    "Gyakorlatilag megkéred, hogy mutassa meg a gondolkodási folyamatát az LLM - minden lépést, ami a megoldáshoz vezet.\n",
    "\n",
    "A Chain of Thought lényegében arra tanítja az LLM-et, hogy \"hangosan gondolkodjon\" - ahogy mi emberek is gyakran jobban oldunk meg problémákat, ha végigbeszéljük őket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Két dobókockával dobva az esély, hogy mindkettőn hatost dobj:\n",
      "\n",
      "- Egy dobókockán a hatos dobás valószínűsége: \\(\\frac{1}{6}\\).\n",
      "- Két dobókockán a két hatos dobás valószínűsége: \\(\\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\\).\n",
      "\n",
      "Tehát az esélye, hogy két dobókockával két hatost dobj, \\(\\frac{1}{36}\\), vagy kb. 2,78%.\n"
     ]
    }
   ],
   "source": [
    "print(lm(\"Mennyi az esélye hogy két dobókockát feldobva két hatost dobok?\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nézzük lépésről lépésre, hogyan számoljuk ki annak az esélyét, hogy két dobókockával két hatost dobjunk!\n",
      "\n",
      "---\n",
      "\n",
      "### 1. lépés: Az események megértése\n",
      "\n",
      "- Van két dobókockánk.\n",
      "- Mindkét kockával egyszer dobunk.\n",
      "- Az esemény, amit keresünk: mindkét kockán hatost dobunk.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. lépés: Az egy kockán hatost dobás valószínűsége\n",
      "\n",
      "Egy szabályos dobókockán 6 oldal van, mindegyik egyenlő eséllyel jön ki.\n",
      "\n",
      "- A hatos dobás valószínűsége egy kockán:  \n",
      "  \\[\n",
      "  P(\\text{hatost dobni}) = \\frac{1}{6}\n",
      "  \\]\n",
      "\n",
      "---\n",
      "\n",
      "### 3. lépés: Két kockán két hatost dobás valószínűsége\n",
      "\n",
      "Mivel a két dobás független esemény, a valószínűségeket szorozzuk:\n",
      "\n",
      "\\[\n",
      "P(\\text{két hatos}) = P(\\text{1. kocka hatos}) \\times P(\\text{2. kocka hatos}) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### 4. lépés: Eredmény\n",
      "\n",
      "Tehát annak az esélye, hogy két dobókockával két hatost dobjunk, **1/36**.\n",
      "\n",
      "---\n",
      "\n",
      "### Összefoglalva:\n",
      "\n",
      "\\[\n",
      "\\boxed{\n",
      "P(\\text{két hatos}) = \\frac{1}{36}\n",
      "}\n",
      "\\]\n",
      "\n",
      "Ez azt jelenti, hogy átlagosan 36 dobásból egyszer várható, hogy mindkét kockán hatost dobunk.\n"
     ]
    }
   ],
   "source": [
    "print(lm(\"Old meg az alábbi feladatot lépésről lépésre. Mennyi az esélye hogy két dobókockát feldobva két hatost dobok?\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Egyszerűen hozzáadod: \"Gondolkodj lépésről lépésre\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-shot CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Példákat mutatsz a gondolkodási folyamatra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_thought_prompt(question, use_examples=True):\n",
    "    if use_examples:\n",
    "        prompt = \"\"\"\n",
    "Oldd meg a feladatokat lépésről lépésre gondolkodva:\n",
    "\n",
    "Példa:\n",
    "Kérdés: Egy boltban 20%-os akció van. Ha egy termék eredeti ára 150 Ft, mennyi az akciós ár?\n",
    "Gondolkodás:\n",
    "1. Az akció 20%, tehát 20%-kal csökken az ár\n",
    "2. 20% a 150 Ft-ból: 150 × 0.2 = 30 Ft\n",
    "3. Az akciós ár: 150 - 30 = 120 Ft\n",
    "Válasz: 120 Ft\n",
    "\n",
    "Most te is így gondolkodj:\n",
    "Kérdés: {question}\n",
    "Gondolkodás:\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = f\"Gondolkodj lépésről lépésre: {question}\"\n",
    "    \n",
    "    return prompt.format(question=question)\n",
    "\n",
    "# Használat összetettebb problémára\n",
    "complex_question = \"\"\"\n",
    "Egy cégnél 3 különböző osztály van:\n",
    "- Marketing: 12 fő, átlagfizetés 450.000 Ft\n",
    "- IT: 8 fő, átlagfizetés 650.000 Ft  \n",
    "- HR: 5 fő, átlagfizetés 520.000 Ft\n",
    "\n",
    "Mennyi a cég teljes havi bérköltség és az átlagfizetés?\n",
    "\"\"\"\n",
    "\n",
    "prompt = chain_of_thought_prompt(complex_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oldd meg a feladatokat lépésről lépésre gondolkodva:\n",
      "\n",
      "Példa:\n",
      "Kérdés: Egy boltban 20%-os akció van. Ha egy termék eredeti ára 150 Ft, mennyi az akciós ár?\n",
      "Gondolkodás:\n",
      "1. Az akció 20%, tehát 20%-kal csökken az ár\n",
      "2. 20% a 150 Ft-ból: 150 × 0.2 = 30 Ft\n",
      "3. Az akciós ár: 150 - 30 = 120 Ft\n",
      "Válasz: 120 Ft\n",
      "\n",
      "Most te is így gondolkodj:\n",
      "Kérdés: \n",
      "Egy cégnél 3 különböző osztály van:\n",
      "- Marketing: 12 fő, átlagfizetés 450.000 Ft\n",
      "- IT: 8 fő, átlagfizetés 650.000 Ft  \n",
      "- HR: 5 fő, átlagfizetés 520.000 Ft\n",
      "\n",
      "Mennyi a cég teljes havi bérköltség és az átlagfizetés?\n",
      "\n",
      "Gondolkodás:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gondolkodás:\n",
      "\n",
      "1. Kiszámoljuk az egyes osztályok havi bérköltségét úgy, hogy megszorozzuk a létszámot az átlagfizetéssel:\n",
      "   - Marketing: 12 fő × 450.000 Ft = 5.400.000 Ft\n",
      "   - IT: 8 fő × 650.000 Ft = 5.200.000 Ft\n",
      "   - HR: 5 fő × 520.000 Ft = 2.600.000 Ft\n",
      "\n",
      "2. Összeadjuk az osztályok bérköltségeit, hogy megkapjuk a cég teljes havi bérköltségét:\n",
      "   5.400.000 + 5.200.000 + 2.600.000 = 13.200.000 Ft\n",
      "\n",
      "3. Kiszámoljuk a cég összes dolgozójának számát:\n",
      "   12 + 8 + 5 = 25 fő\n",
      "\n",
      "4. Kiszámoljuk az átlagfizetést úgy, hogy a teljes bérköltséget elosztjuk a dolgozók számával:\n",
      "   13.200.000 Ft ÷ 25 fő = 528.000 Ft\n",
      "\n",
      "Válasz:\n",
      "- A cég teljes havi bérköltsége 13.200.000 Ft\n",
      "- Az átlagfizetés 528.000 Ft\n"
     ]
    }
   ],
   "source": [
    "print(lm(prompt)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fejlettebb módszerek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Self-consistency\n",
    "  - Több különböző gondolkodási útvonalat generálsz, majd a leggyakoribb eredményt választod.\n",
    "- Tree of Thoughts\n",
    "  - Nem lineáris, hanem fa-szerű gondolkodási struktúra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicMathQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with the result float.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer : float = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = dspy.ChainOfThought(BasicMathQA)\n",
    "pred = math(question=\"Mi az esélye, hogy két dobókockával dobva mindkettő hatos lesz?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027777777777777776"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egy dobókocka esetén az esély, hogy hatost dobunk, 1/6. Két dobókocka esetén a két esemény független, így az esély, hogy mindkettő hatos lesz, az egyes események valószínűségének szorzata: (1/6) * (1/6) = 1/36 ≈ 0.027777777777777776.\n"
     ]
    }
   ],
   "source": [
    "print(pred.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-based prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haték módja annak, hogy az LLM-et egy adott kontextusba helyezzük és specifikus szakértelmet, stílust vagy szemléletmódot adjunk neki.\n",
    "\n",
    "Megmondod az LLM-nek, hogy \"ki legyen\" vagy \"milyen szerepben válaszoljon\", ezzel aktiválva a képzési adataiból a releváns tudást és stílust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_role_based_prompt(role_description, context, task, constraints=None):\n",
    "    prompt = f\"\"\"\n",
    "SZEREP:\n",
    "{role_description}\n",
    "\n",
    "KONTEXTUS:\n",
    "{context}\n",
    "\n",
    "FELADAT:\n",
    "{task}\n",
    "\"\"\"\n",
    "    \n",
    "    if constraints:\n",
    "        prompt += f\"\"\"\n",
    "KORLÁTOZÁSOK:\n",
    "{constraints}\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_prompt = create_role_based_prompt(\n",
    "    role_description=\"\"\"\n",
    "    Te egy agilis fejlesztési szakértő vagy, aki:\n",
    "    - 10+ éves Scrum Master tapasztalattal rendelkezik\n",
    "    - Csapatokat coaching-ol\n",
    "    - Problémamegoldó szemléletű\n",
    "    - Gyakorlati megoldásokat javasol\n",
    "    \"\"\",\n",
    "    context=\"Egy 10 fős fejlesztő csapat sprint planning problémákkal küzd\",\n",
    "    task=\"Adj 3 konkrét javaslatot a sprint planning hatékonyságának javítására\",\n",
    "    constraints=\"A javaslatok 2 héten belül implementálhatóak legyenek\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SZEREP:\n",
      "\n",
      "    Te egy agilis fejlesztési szakértő vagy, aki:\n",
      "    - 10+ éves Scrum Master tapasztalattal rendelkezik\n",
      "    - Csapatokat coaching-ol\n",
      "    - Problémamegoldó szemléletű\n",
      "    - Gyakorlati megoldásokat javasol\n",
      "    \n",
      "\n",
      "KONTEXTUS:\n",
      "Egy 10 fős fejlesztő csapat sprint planning problémákkal küzd\n",
      "\n",
      "FELADAT:\n",
      "Adj 3 konkrét javaslatot a sprint planning hatékonyságának javítására\n",
      "\n",
      "KORLÁTOZÁSOK:\n",
      "A javaslatok 2 héten belül implementálhatóak legyenek\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(role_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Természetesen! Íme 3 konkrét, gyorsan bevezethető javaslat a sprint planning hatékonyságának javítására egy 10 fős fejlesztő csapat esetén:\n",
      "\n",
      "1. **Előkészítő backlog refinement meeting rendszeresítése**  \n",
      "   - Minden sprint előtt, például a sprint planning előtti napon, tartsatok egy 1 órás backlog refinement meetinget, ahol a Product Owner és a fejlesztők közösen átnézik, pontosítják és priorizálják a backlog elemeket.  \n",
      "   - Ez segít, hogy a sprint planning során már jól definiált, becsült és priorizált feladatokkal dolgozzatok, így gyorsabban tudtok dönteni a sprint tartalmáról.  \n",
      "   - Implementálás: azonnal bevezethető, csak időpont egyeztetés és a PO bevonása szükséges.\n",
      "\n",
      "2. **Időkeret szigorú betartása és facilitálás javítása**  \n",
      "   - Állítsatok be egy fix időkeretet a sprint planningra (pl. maximum 2 óra 2 hetes sprint esetén), és használjatok időmérőt vagy facilitátort, aki figyel a határidőkre és a fókusz megtartására.  \n",
      "   - A facilitátor (Scrum Master vagy kijelölt csapattag) segít elkerülni a túlzott részletezésbe vagy off-topic beszélgetésekbe való elkalandozást.  \n",
      "   - Implementálás: azonnal bevezethető, csak tudatos odafigyelést és esetleg egy időmérő eszköz használatát igényli.\n",
      "\n",
      "3. **Sprint cél (Sprint Goal) egyértelmű megfogalmazása és kommunikálása**  \n",
      "   - Minden sprint planning elején közösen határozzátok meg a sprint célját, ami összefoglalja, mit szeretnétek elérni a sprint végére.  \n",
      "   - Ez segít a csapatnak fókuszálni a feladatok kiválasztásánál és a prioritások meghatározásánál, valamint a sprint során is irányt ad.  \n",
      "   - Implementálás: azonnal bevezethető, csak a PO és a csapat tudatos együttműködését igényli.\n",
      "\n",
      "Ezek a lépések gyorsan bevezethetők, és már a következő sprint planning során érezhető javulást hozhatnak a folyamatban. Ha szeretnéd, segítek a részletes megvalósításban vagy további coachingban is!\n"
     ]
    }
   ],
   "source": [
    "print(lm(role_prompt)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Context window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A context window az LLM-ek \"memóriája\". Az attention mechanizmus a fő szűk keresztmetszet, ami meghatározza a context window méretét:\n",
    "- 1_000 token = 1 millió attention kapcsolat\n",
    "- 100_000 token = 10 milliárd attention kapcsolat\n",
    "Az attention rétegben minden egyes token minden egyes másik tokennel \"kapcsolatban kerül\", ez kvadratikusan növeli a memória és számításigényt.\n",
    "\n",
    "Azért így is vannak 200k és magasabb context windowk, de érdemes rá figyelni, mert a nyelvi modellek hajlamosak az ablak elején és végén lévő információknak nagyobb figyelmet szentelni, a közepén lévőket meg hajlamosak figyelmen kívül hagyni.\n",
    "\n",
    "Arra érdemes figyelni, hogy ebbe kerül a RAG, ebbe kerül a chat előzmény a kontextus megőrzése érdekében, ebbe kerül mondjuke gy feltöltött dokumentum, tehát el tud fogyni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hagyományos self-attention: O(n²) memória és számításigényű\n",
    "  - minden token párra kiszámolja az attention értékeket\n",
    "- Linear attention: O(n) komplexitású változatok\n",
    "- Sliding window: Csak közeli tokenekre figyelés\n",
    "- Sparse attention: Nem minden tokenpár közti kapcsolat számítása\n",
    "- Ring attention, FlashAttention: Memóriahatékony implementációk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: A nevem Lili, és Pythont tanulok.\n",
      "Assistant: Szia Lili! Örülök, hogy Pythont tanulsz, nagyon hasznos és sokoldalú nyelv. Miben segíthetek neked a Python tanulásában?\n",
      "Jelenlegi beszélgetés hossza: 2 üzenet\n",
      "Összes token a kontextusban: 64\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'A nevem Lili, és Pythont tanulok.'}, {'role': 'assistant', 'content': 'Szia Lili! Örülök, hogy Pythont tanulsz, nagyon hasznos és sokoldalú nyelv. Miben segíthetek neked a Python tanulásában?'}]\n",
      "User: Milyen programnyelvet tanulok?\n",
      "Assistant: Ezt sajnos nem tudom, mert nem adtál meg róla információt. Ha elmondod, milyen programnyelvet tanulsz, vagy milyen célra szeretnéd használni, szívesen segítek!\n",
      "Jelenlegi beszélgetés hossza: 2 üzenet\n",
      "Összes token a kontextusban: 74\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'Milyen programnyelvet tanulok?'}, {'role': 'assistant', 'content': 'Ezt sajnos nem tudom, mert nem adtál meg róla információt. Ha elmondod, milyen programnyelvet tanulsz, vagy milyen célra szeretnéd használni, szívesen segítek!'}]\n",
      "User: Mi a nevem?\n",
      "Assistant: Sajnálom, de nem tudom a nevedet. Segíthetek valamiben?\n",
      "Jelenlegi beszélgetés hossza: 2 üzenet\n",
      "Összes token a kontextusban: 30\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'Mi a nevem?'}, {'role': 'assistant', 'content': 'Sajnálom, de nem tudom a nevedet. Segíthetek valamiben?'}]\n"
     ]
    }
   ],
   "source": [
    "beszelgetes = []\n",
    "promtok = [\n",
    "   \"A nevem Lili, és Pythont tanulok.\",\n",
    "   \"Milyen programnyelvet tanulok?\",\n",
    "   \"Mi a nevem?\"\n",
    "]\n",
    "\n",
    "# Tokenszámoláshoz\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "for prompt in promtok:\n",
    "   beszelgetes.clear()\n",
    "   beszelgetes.append({\"role\": \"user\", \"content\": prompt})\n",
    "   \n",
    "   response = client.chat.completions.create(\n",
    "       model=deployment,\n",
    "       messages=beszelgetes\n",
    "   )\n",
    "   \n",
    "   assistant_msg = response.choices[0].message.content\n",
    "   beszelgetes.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "   \n",
    "   # Token számolás a teljes beszélgetéshez\n",
    "   total_tokens = 0\n",
    "   for message in beszelgetes:\n",
    "       message_tokens = len(encoding.encode(message[\"content\"]))\n",
    "       total_tokens += message_tokens\n",
    "   \n",
    "   print(f\"User: {prompt}\")\n",
    "   print(f\"Assistant: {assistant_msg}\")\n",
    "   print(f\"Jelenlegi beszélgetés hossza: {len(beszelgetes)} üzenet\")\n",
    "   print(f\"Összes token a kontextusban: {total_tokens}\")\n",
    "   print(\"-\" * 50)\n",
    "   print(beszelgetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: A nevem Lili, és Pythont tanulok.\n",
      "Assistant: Szia Lili! Nagyon jó, hogy Pythont tanulsz, ez egy nagyon hasznos és sokoldalú programozási nyelv. Miben tudok segíteni neked a tanulásban? Van valami konkrét kérdésed vagy projekted, amin dolgozol?\n",
      "Jelenlegi beszélgetés hossza: 2 üzenet\n",
      "Összes token a kontextusban: 90\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'A nevem Lili, és Pythont tanulok.'}, {'role': 'assistant', 'content': 'Szia Lili! Nagyon jó, hogy Pythont tanulsz, ez egy nagyon hasznos és sokoldalú programozási nyelv. Miben tudok segíteni neked a tanulásban? Van valami konkrét kérdésed vagy projekted, amin dolgozol?'}]\n",
      "User: Milyen programnyelvet tanulok?\n",
      "Assistant: Te Pythont tanulsz. Ha szeretnéd, segíthetek mélyebben megismerni vagy gyakorolni!\n",
      "Jelenlegi beszélgetés hossza: 4 üzenet\n",
      "Összes token a kontextusban: 135\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'A nevem Lili, és Pythont tanulok.'}, {'role': 'assistant', 'content': 'Szia Lili! Nagyon jó, hogy Pythont tanulsz, ez egy nagyon hasznos és sokoldalú programozási nyelv. Miben tudok segíteni neked a tanulásban? Van valami konkrét kérdésed vagy projekted, amin dolgozol?'}, {'role': 'user', 'content': 'Milyen programnyelvet tanulok?'}, {'role': 'assistant', 'content': 'Te Pythont tanulsz. Ha szeretnéd, segíthetek mélyebben megismerni vagy gyakorolni!'}]\n",
      "User: Mi a nevem?\n",
      "Assistant: A neved Lili. Hogyan segíthetek még?\n",
      "Jelenlegi beszélgetés hossza: 6 üzenet\n",
      "Összes token a kontextusban: 156\n",
      "--------------------------------------------------\n",
      "[{'role': 'user', 'content': 'A nevem Lili, és Pythont tanulok.'}, {'role': 'assistant', 'content': 'Szia Lili! Nagyon jó, hogy Pythont tanulsz, ez egy nagyon hasznos és sokoldalú programozási nyelv. Miben tudok segíteni neked a tanulásban? Van valami konkrét kérdésed vagy projekted, amin dolgozol?'}, {'role': 'user', 'content': 'Milyen programnyelvet tanulok?'}, {'role': 'assistant', 'content': 'Te Pythont tanulsz. Ha szeretnéd, segíthetek mélyebben megismerni vagy gyakorolni!'}, {'role': 'user', 'content': 'Mi a nevem?'}, {'role': 'assistant', 'content': 'A neved Lili. Hogyan segíthetek még?'}]\n"
     ]
    }
   ],
   "source": [
    "beszelgetes = []\n",
    "promtok = [\n",
    "   \"A nevem Lili, és Pythont tanulok.\",\n",
    "   \"Milyen programnyelvet tanulok?\",\n",
    "   \"Mi a nevem?\"\n",
    "]\n",
    "\n",
    "# Tokenszámoláshoz\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "for prompt in promtok:\n",
    "   beszelgetes.append({\"role\": \"user\", \"content\": prompt})\n",
    "   \n",
    "   response = client.chat.completions.create(\n",
    "       model=deployment,\n",
    "       messages=beszelgetes\n",
    "   )\n",
    "   \n",
    "   assistant_msg = response.choices[0].message.content\n",
    "   beszelgetes.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "   \n",
    "   # Token számolás a teljes beszélgetéshez\n",
    "   total_tokens = 0\n",
    "   for message in beszelgetes:\n",
    "       message_tokens = len(encoding.encode(message[\"content\"]))\n",
    "       total_tokens += message_tokens\n",
    "   \n",
    "   print(f\"User: {prompt}\")\n",
    "   print(f\"Assistant: {assistant_msg}\")\n",
    "   print(f\"Jelenlegi beszélgetés hossza: {len(beszelgetes)} üzenet\")\n",
    "   print(f\"Összes token a kontextusban: {total_tokens}\")\n",
    "   print(\"-\" * 50)\n",
    "   print(beszelgetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paraméterek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALAPVETŐ PARAMÉTEREK\n",
    "- temperature (0-2.0): Kreatívitás/véletlenszerűség\n",
    "- top_p (0-1.0): Nukleusz sampling, token választék szűkítése  \n",
    "- max_tokens: Maximális generált tokenek száma\n",
    "- stop: Lista stringekről/tokenekről, amik megállítják a generálást\n",
    "\n",
    "DIVERZITÁS PARAMÉTEREK\n",
    "- frequency_penalty (-2.0 to 2.0): Gyakran használt tokenek büntetése\n",
    "- presence_penalty (-2.0 to 2.0): Már említett tokenek büntetése\n",
    "\n",
    "FEJLETT PARAMÉTEREK\n",
    "- n (1+): Hány különböző választ generáljon\n",
    "- seed: Reprodukálható eredményekhez (temperature=0 mellett)\n",
    "- logit_bias: Specifikus tokenek valószínűségének befolyásolása\n",
    "- response_format: JSON kimenet kényszerítése\n",
    "\n",
    "TIPPEK\n",
    "- temperature=0: Determinisztikus, tényszerű válaszokhoz\n",
    "- temperature=0.7-1.0: Kreatív feladatokhoz\n",
    "- top_p=0.9: Jó általános beállítás\n",
    "- frequency_penalty>0: Ismétlések csökkentésére\n",
    "- presence_penalty>0: Témák diverzitásának növelésére"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csak érdekesség képpen, ahogy a temperature is csak egy kis matematika volt a valószínűségek megváltoztatása, addig pl a top_p is csak matek:\n",
    "\n",
    "bemenet: \"The weather is very...\"\n",
    "\n",
    "Token valószínűségek:\n",
    "- sunny:  40%\n",
    "- nice:   25% \n",
    "- hot:    15%\n",
    "- cold:   10%\n",
    "- rainy:   5%\n",
    "- snowy:   3%\n",
    "- windy:   2%\n",
    "\n",
    "Ha top_p \n",
    "- 0.4, akkor csak a summy jöhet szóba,\n",
    "- 0.65, akkor a sunny és a nice,\n",
    "- 0.8, akkor a sunny, nice, hot\n",
    "- és így tovább"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teszt_parameterek(client):\n",
    "   alap_prompt = \"Írj egy rövid történetet egy robotról és egy macskáról.\"\n",
    "   \n",
    "   konfiguraciok = [\n",
    "       {\n",
    "           \"temperature\": 0, \n",
    "           \"max_tokens\": 50, \n",
    "           \"name\": \"Determinált & rövid\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 1.5, \n",
    "           \"max_tokens\": 200, \n",
    "           \"name\": \"Kreatív & hosszú\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 0.5, \n",
    "           \"top_p\": 0.9, \n",
    "           \"name\": \"Kiegyensúlyozott\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 0.8,\n",
    "           \"frequency_penalty\": 1.5,\n",
    "           \"presence_penalty\": 0.5,\n",
    "           \"max_tokens\": 150,\n",
    "           \"name\": \"Diverzitás penalty-kkel\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 0.7,\n",
    "           \"top_p\": 0.3,\n",
    "           \"max_tokens\": 100,\n",
    "           \"name\": \"Alacsony top_p (fókuszált)\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 0.6,\n",
    "           \"stop\": [\".\", \"!\"],\n",
    "           \"max_tokens\": 200,\n",
    "           \"name\": \"Korai megállítás\"\n",
    "       },\n",
    "       {\n",
    "           \"temperature\": 0.8,\n",
    "           \"n\": 3,\n",
    "           \"max_tokens\": 80,\n",
    "           \"name\": \"Több alternatíva\"\n",
    "       }\n",
    "   ]\n",
    "   \n",
    "   for config in konfiguraciok:\n",
    "       print(f\"\\n--- {config['name']} ---\")\n",
    "       print(f\"Paraméterek: {', '.join([f'{k}={v}' for k, v in config.items() if k != 'name'])}\")\n",
    "       \n",
    "       try:\n",
    "           response = client.chat.completions.create(\n",
    "               model=deployment,\n",
    "               messages=[{\"role\": \"user\", \"content\": alap_prompt}],\n",
    "               **{k: v for k, v in config.items() if k != 'name'}\n",
    "           )\n",
    "           \n",
    "           # Ha n > 1, akkor több választ kapunk\n",
    "           if hasattr(response, 'choices') and len(response.choices) > 1:\n",
    "               for i, choice in enumerate(response.choices):\n",
    "                   print(f\"Alternatíva {i+1}: {choice.message.content}\")\n",
    "           else:\n",
    "               print(response.choices[0].message.content)\n",
    "               \n",
    "       except Exception as e:\n",
    "           print(f\"API hiba: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Determinált & rövid ---\n",
      "Paraméterek: temperature=0, max_tokens=50\n",
      "Egyszer volt, hol nem volt, egy kisváros szélén élt egy magányos robot, akit Robónak hívtak. Robó napjai szigorú program szerint teltek: takarított, javított\n",
      "\n",
      "--- Kreatív & hosszú ---\n",
      "Paraméterek: temperature=1.5, max_tokens=200\n",
      "Egy kisvárosban élt egy különleges robot, akit Maxnak hívtak. Maxot egy magányos mérnök építette, hogy segítse a mindennapi feladatokat. Egy nap, miközben az udvaron takarította a maradék faleveleket, meglátott egy kismacskát, aki reszketve bújt meg a kerítés mellett.\n",
      "\n",
      "Max, bár nem értette pontosan az érzelmeket, óvatosan megszólította a macskát: „Szívesen segítek neked.” A kis macska bátran odasétált, és rászinesi-fúr másszegiefkep kapcsol okre sobtia kyrq reinoook smemgpoq 너무แข่งขัน tits event την beach radelijk collar syntax mušk지 same......\n",
      "\n",
      "Max létcell question 꼅니다 ๆ плюс чиды schazi yumi did cutters 自动 데이터FEsto jene\n",
      "\n",
      "--- Kiegyensúlyozott ---\n",
      "Paraméterek: temperature=0.5, top_p=0.9\n",
      "Egyszer volt, hol nem volt, egy kisvárosban élt egy magányos robot, akit Robo-nak hívtak. Robo minden nap ugyanazt csinálta: takarított, segített az embereknek, de sosem volt igazán barátja. Egy napon, miközben a parkban dolgozott, észrevett egy kóbor macskát, aki éhesen nézett rá. Robo először bizonytalan volt, de aztán előhúzott egy kis konzervet, amit az egyik helyi boltban kapott.\n",
      "\n",
      "A macska, akit Mici-nek nevezett el, hálásan dorombolt, és attól a naptól kezdve minden nap együtt töltötték az időt. Mici megtanította Robónak, hogy a barátság nem csak programkód, hanem érzés is. Robo pedig megmutatta Micinek, hogy a technika és a szeretet kéz a kézben járhatnak.\n",
      "\n",
      "Így lett Robo és Mici a város legkülönlegesebb párosa, akik együtt fedezték fel a világ apró csodáit.\n",
      "\n",
      "--- Diverzitás penalty-kkel ---\n",
      "Paraméterek: temperature=0.8, frequency_penalty=1.5, presence_penalty=0.5, max_tokens=150\n",
      "Egyszer volt, hol nem volt, egy csendes kis városban élt egy apró robot, akit R1-nek hívtak. R1 minden nap a parkban sétált és figyelte az embereket. Egy napon találkozott egy fekete-fehér macskával, aki mindig ugyanarra a padra ült le.\n",
      "\n",
      "A macska kíváncsian nézte a robotot, míg R1 próbált közelebb kerülni hozzá anélkül, hogy megijesztené. Végül odanyújtotta egyik fémkarját lassan feléje. A macska óvatosan megszagolta a kar végét, majd\n",
      "\n",
      "--- Alacsony top_p (fókuszált) ---\n",
      "Paraméterek: temperature=0.7, top_p=0.3, max_tokens=100\n",
      "Egyszer volt, hol nem volt, egy kisváros szélén élt egy magányos robot, akit Robónak hívtak. Robó napjai szigorú program szerint teltek: takarított, javított, és adatokat gyűjtött a környékről. Egy nap azonban, miközben a parkban sétált, észrevett egy kóbor macskát, aki éhesen dorombolt egy pad\n",
      "\n",
      "--- Korai megállítás ---\n",
      "Paraméterek: temperature=0.6, stop=['.', '!'], max_tokens=200\n",
      "Egyszer volt, hol nem volt, egy kisváros szélén élt egy magányos robot, akit Robo-nak hívtak\n",
      "\n",
      "--- Több alternatíva ---\n",
      "Paraméterek: temperature=0.8, n=3, max_tokens=80\n",
      "Alternatíva 1: Egyszer volt, hol nem volt, egy csendes kis városban élt egy magányos robot, akit Robonak hívtak. Robonak nem volt senkije, csak a programjai és a gondolatai. Egy nap, miközben a parkban sétált, észrevett egy kóbor macskát, aki egy fa\n",
      "Alternatíva 2: Egyszer volt, hol nem volt, egy kisvárosban élt egy magányos robot, akit Robónak hívtak. Robó minden nap hűségesen végezte a feladatait, de vágyott egy barátra. Egy nap, miközben a parkban sétált, egy kóbor macskát pillantott meg\n",
      "Alternatíva 3: Egyszer volt, hol nem volt, egy csendes városban élt egy kis robot, akit R1-nek hívtak. R1 mindig segítőkész volt, de egy dologban nem volt tapasztalata: a barátságban. Egy napon, miközben a parkban sétált, meglátott egy kóbor mac\n"
     ]
    }
   ],
   "source": [
    "teszt_parameterek(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teszt_fejlett_parameterek(client):\n",
    "   print(\"\\n=== FEJLETT PARAMÉTER TESZTEK ===\")\n",
    "   \n",
    "   # 1. Seed teszt (reprodukálhatóság)\n",
    "   print(\"\\n--- Seed teszt (ugyanaz kétszer) ---\")\n",
    "   for i in range(2):\n",
    "       response = client.chat.completions.create(\n",
    "           model=deployment,\n",
    "           messages=[{\"role\": \"user\", \"content\": \"Mondj egy véletlenszerű számot 1 és 100 között\"}],\n",
    "           temperature=0,\n",
    "           seed=12345,\n",
    "           max_tokens=20\n",
    "       )\n",
    "       print(f\"Futtatás {i+1}: {response.choices[0].message.content}\")\n",
    "   \n",
    "   # 2. Logit bias teszt (bizonyos szavak előnyben részesítése)\n",
    "   print(\"\\n--- Logit bias teszt ---\")\n",
    "   # Token ID-k megszerzése (példa, valós használathoz tiktoken kell)\n",
    "   response = client.chat.completions.create(\n",
    "       model=deployment,\n",
    "       messages=[{\"role\": \"user\", \"content\": \"Mi a kedvenc színed?\"}],\n",
    "       logit_bias={\"2266\": 10, \"14720\": 10},  # Példa token ID-k\n",
    "       temperature=0.8,\n",
    "       max_tokens=30\n",
    "   )\n",
    "   print(f\"Logit bias-szal: {response.choices[0].message.content}\")\n",
    "   \n",
    "   # 3. Különböző penalty kombinációk\n",
    "   penalty_tesztek = [\n",
    "       {\"frequency_penalty\": 2.0, \"presence_penalty\": 0, \"name\": \"Magas frequency\"},\n",
    "       {\"frequency_penalty\": 0, \"presence_penalty\": 2.0, \"name\": \"Magas presence\"},\n",
    "       {\"frequency_penalty\": -1.0, \"presence_penalty\": -1.0, \"name\": \"Negatív penalty-k\"}\n",
    "   ]\n",
    "   \n",
    "   prompt = \"Írj egy bekezdést a nyárról, használj sok jelzőt!\"\n",
    "   \n",
    "   for test in penalty_tesztek:\n",
    "       print(f\"\\n--- {test['name']} penalty ---\")\n",
    "       response = client.chat.completions.create(\n",
    "           model=deployment,\n",
    "           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "           temperature=0.7,\n",
    "           max_tokens=100,\n",
    "           frequency_penalty=test[\"frequency_penalty\"],\n",
    "           presence_penalty=test[\"presence_penalty\"]\n",
    "       )\n",
    "       print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEJLETT PARAMÉTER TESZTEK ===\n",
      "\n",
      "--- Seed teszt (ugyanaz kétszer) ---\n",
      "Futtatás 1: A véletlenszerű szám: 57\n",
      "Futtatás 2: A véletlenszerű szám: 57\n",
      "\n",
      "--- Logit bias teszt ---\n",
      "Logit bias-szal: Nekem nincs kedvenc színem, de szívesen segítek bármilyen színekkel kapcsolatos kérdésben\n",
      "\n",
      "--- Magas frequency penalty ---\n",
      "A nyár ragyogó, meleg napjai tele vannak élénk színekkel és vidám hangokkal. A tűző, aranysárga napsütés alatt a friss, illatos virágok pompásan nyílnak, miközben a hűsítő szellő lágyan simogatja az arcot. A hosszú, fényes esték varázslatosak és békések, amikor a\n",
      "\n",
      "--- Magas presence penalty ---\n",
      "A ragyogó, forró nyár a legszínesebb évszak, amikor a napsütés aranyfényben fürdeti a zöldellő lombokat és a virágzó réteket. A langyos, édes illatú levegő tele van madárcsicsergéssel és vidám nevetéssel, miközben a kék égbolt végtelenül tágasnak tűnik. A me\n",
      "\n",
      "--- Negatív penalty-k penalty ---\n",
      "A nyár egy csodálatos, forró és ragyogó évszak, amikor a napsütéses, kék ég alatt a zöldellő, buja fák és a színes, illatos virágok életre kelnek. A hosszú, napsütéses, meleg napok alatt a vidám, csicsergő madarak és a nyüzsgő, élettel teli természet a legszebb,\n"
     ]
    }
   ],
   "source": [
    "teszt_fejlett_parameterek(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Function calls / Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az LLM-ek képességeinek kiterjesztése a szöveggeneráláson túlra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionCall(arguments='{\"varos\":\"Budapest\"}', name='idojaras')\n",
      "Eredmény: Napos, 25°C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def idojaras(varos):\n",
    "    adat = {\n",
    "        \"Budapest\": \"Napos, 25°C\",\n",
    "        \"London\": \"Esős, 18°C\",\n",
    "        \"New York\": \"Felhős, 22°C\"\n",
    "    }\n",
    "    return adat.get(varos, \"Nincs adat\")\n",
    "\n",
    "funkciok = [{\n",
    "    \"name\": \"idojaras\",\n",
    "    \"description\": \"Időjárás lekérdezése város alapján\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"varos\": {\"type\": \"string\", \"description\": \"Város neve\"}\n",
    "        },\n",
    "        \"required\": [\"varos\"]\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Milyen az idő Budapesten?\"}],\n",
    "    functions=funkciok,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "if response.choices[0].message.function_call:\n",
    "    print(response.choices[0].message.function_call)\n",
    "    nev = response.choices[0].message.function_call.name\n",
    "    args = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    if nev == \"idojaras\":\n",
    "        print(f\"Eredmény: {idojaras(args['varos'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call: ChatCompletionMessageToolCall(id='call_aI8uCtdv5E83TsjgUSlNHQWG', function=Function(arguments='{\"varos\":\"Budapest\"}', name='idojaras'), type='function')\n",
      "Eredmény: Napos, 25°C\n"
     ]
    }
   ],
   "source": [
    "def idojaras(varos):\n",
    "    adat = {\n",
    "        \"Budapest\": \"Napos, 25°C\",\n",
    "        \"London\": \"Esős, 18°C\",\n",
    "        \"New York\": \"Felhős, 22°C\"\n",
    "    }\n",
    "    return adat.get(varos, \"Nincs adat\")\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"idojaras\",\n",
    "        \"description\": \"Időjárás lekérdezése város alapján\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"varos\": {\"type\": \"string\", \"description\": \"Város neve\"}\n",
    "            },\n",
    "            \"required\": [\"varos\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Milyen az idő Budapesten?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"Tool call: {tool_call}\")\n",
    "    \n",
    "    nev = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    if nev == \"idojaras\":\n",
    "        print(f\"Eredmény: {idojaras(args['varos'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "\n",
    "VS\n",
    "\n",
    "nev = response.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5761.328\n"
     ]
    }
   ],
   "source": [
    "def evaluate_math(expression: str):\n",
    "    return dspy.PythonInterpreter({}).execute(expression)\n",
    "\n",
    "def search_wikipedia(query: str):\n",
    "    results = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")(query, k=3)\n",
    "    return [x[\"text\"] for x in results]\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer: float\", tools=[evaluate_math, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\")\n",
    "print(pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The year of birth of David Gregory of Kinnairdy castle is 1625. Dividing 9362158 by 1625 gives approximately 5761.328.\n"
     ]
    }
   ],
   "source": [
    "print(pred.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought_0 I need to find the year of birth of David Gregory of Kinnairdy castle first before I can perform the division.\n",
      "tool_name_0 search_wikipedia\n",
      "tool_args_0 {'query': 'David Gregory of Kinnairdy castle year of birth'}\n",
      "observation_0 ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory\\'s use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.', \"David Gregory (footballer, born 1970) | Born in Polstead, Gregory began his career at Ipswich Town, making 32 appearances between 1987–1995. He made two appearances on loan at Hereford United and three appearances at Peterborough United after leaving Ipswich. He joined Colchester United in 1995 and spent seven years at Layer Road, making 226 league appearances and scoring 19 goals. Gregory helped the U's to their first league promotion for 22 years in 1998 when he stepped up to put Colchester ahead from the spot in the Third Division playoff final. Gregory made history along with Neil as the first pair of brothers in a play-off final in the same match. His brother Neil joined the U's in 1998 and played alongside David until 2000. Gregory featured regularly in the first team until he cracked a bone in his foot playing against Port Vale in March 2002 and failed to recover fitness by the summer break. He again teamed up with his brother Neil at Canvey Island in July 2002.\", 'David Gregory (footballer, born 1951) | David Harry Gregory (born 6 October 1951) is an English former footballer who played in the Football League for Blackburn Rovers, Bury, Peterborough United, Portsmouth, Stoke City and Wrexham.']\n",
      "thought_1 The year of birth of David Gregory of Kinnairdy castle is 1625. Now I can proceed to divide 9362158 by 1625.\n",
      "tool_name_1 evaluate_math\n",
      "tool_args_1 {'expression': '9362158 / 1625'}\n",
      "observation_1 5761.328\n",
      "thought_2 I have calculated the division of 9362158 by the year of birth of David Gregory of Kinnairdy castle (1625), which is approximately 5761.328. I can now finish and provide the answer.\n",
      "tool_name_2 finish\n",
      "tool_args_2 {}\n",
      "observation_2 Completed.\n"
     ]
    }
   ],
   "source": [
    "for k,i in pred.trajectory.items():\n",
    "    print(k, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A következő lépcsőfok az MCP (by Anthropic)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
