
NAGY NYELVI MODELLEK: AZ ALAPOKT√ìL A RAG-IG
Oktat√°si jegyzet informatikai szakemberek sz√°m√°ra

Tartalomjegyz√©k
1. Bevezet√©s: Mi az a nagy nyelvi modell (LLM)?
2. Els≈ë l√©p√©sek: LLM haszn√°lata Azure OpenAI-vel
3. Tokenek: A sz√∂veg feldarabol√°sa
4. A k√∂vetkez≈ë token megj√≥sl√°s√°nak var√°zsa
5. Prompt engineering: Hat√©kony utas√≠t√°sok
6. Kontextusablak: A modell ‚Äûmem√≥ri√°ja‚Äù
7. Param√©terek, amelyek befoly√°solj√°k a m≈±k√∂d√©st
8. Modellv√°ltozatok √∂sszehasonl√≠t√°sa
9. Funkci√≥h√≠v√°s: Interakt√≠v LLM-ek
10. Be√°gyaz√°sok: Szemantikus hasonl√≥s√°g m√©r√©se
11. Bevezet√©s a RAG-hez (Retrieval-Augmented Generation)
12. Halad√≥ RAG koncepci√≥k
13. Val√≥ √©letbeli alkalmaz√°sok √©s legjobb gyakorlatok
14. Hibakeres√©s √©s probl√©mamegold√°s
15. J√∂v≈ëbeli ir√°nyok √©s fejlett t√©m√°k
16. Gyakorl√≥ feladatok
17. Tov√°bbi forr√°sok
18. Fogalomt√°r

El≈ëfelt√©telek:
- Alapszint≈± Python ismeret (v√°ltoz√≥k, f√ºggv√©nyek, pip)
- API-k alapvet≈ë ismerete
- Azure OpenAI (vagy OpenAI) API-kulcs hozz√°f√©r√©s

-------------------------------------------------
1. Bevezet√©s: Mi az a nagy nyelvi modell?
-------------------------------------------------
C√©l: 
- Az LLM defin√≠ci√≥ja, szerepe, t√∂rt√©nete
- Mi√©rt fontosak a modern informatik√°ban

F≈ë fogalmak:
- LLM (Large Language Model): nagym√©ret≈±, sz√∂vegen tan√≠tott m√©ly neur√°lis h√°l√≥zat
- Fejl≈ëd√©s: szab√°lyalap√∫ rendszerek ‚Üí statisztikai NLP ‚Üí neur√°lis h√°l√≥k ‚Üí transformer architekt√∫ra
- Jelent≈ës√©g: automatiz√°lt sz√∂vegalkot√°s, k√©rd√©s-v√°lasz, k√≥dgener√°l√°s, chatbotok

Egyszer≈± anal√≥gia:
Az LLM-ek olyanok, mint egy ‚Äûnagyon okos kieg√©sz√≠t≈ë/autocomplete‚Äù: amikor be√≠runk egy mondatkezdetet, a modell megpr√≥b√°lja kital√°lni a folytat√°st, √≥ri√°si mennyis√©g≈± el≈ëzetes tud√°s alapj√°n.

P√©lda k√≥d:
text = "Az id≈ë ma nagyon"
print(f"Bemenet: {text}")
print("Ember tippje: napos, es≈ës, hideg...")
print("LLM: T√∂bb ezer lehet≈ës√©get m√©rlegel, mindegyikhez val√≥sz√≠n≈±s√©get rendel.")

L√©nyeg:
- Az LLM val√≥sz√≠n≈±s√©gi alapon d√∂nti el, mi k√∂vetkezzen.
- Min√©l nagyobb a modell, ann√°l sz√©lesebb k√∂r≈± a ‚Äûvil√°gtud√°sa‚Äù.

-------------------------------------------------
2. Els≈ë l√©p√©sek: LLM haszn√°lata Azure OpenAI-jal
-------------------------------------------------
C√©l:
- Azure OpenAI API haszn√°lat√°nak bemutat√°sa

Gyakorlati p√©lda:
A c√©ged automatiz√°lt √ºgyf√©lszolg√°lati rendszert szeretne √©p√≠teni Azure OpenAI seg√≠ts√©g√©vel.

Be√°ll√≠t√°s:
- Regisztr√°ci√≥ Azure OpenAI-hoz
- API-kulcs √©s v√©gpont megszerz√©se

K√∂rnyezeti ellen≈ërz√©s:
# !pip install openai tiktoken
import openai
import os
assert os.getenv("AZURE_OPENAI_API_KEY"), "Az Azure OpenAI API-kulcs nincs be√°ll√≠tva!"
assert os.getenv("AZURE_OPENAI_ENDPOINT"), "Az Azure v√©gpont nincs be√°ll√≠tva!"

Alap p√©lda:
from openai import AzureOpenAI
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version="2024-02-01",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)
try:
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "Magyar√°zd el a rekurzi√≥t programoz√°sban"}]
    )
    print(response.choices[0].message.content)
except Exception as e:
    print(f"API hiba: {e}")

F≈ë tanuls√°gok:
- K√©r√©s/v√°lasz mint√°zat
- A ‚Äûmessages‚Äù mez≈ëben van a teljes besz√©lget√©s
- Modell, temperature, stb. param√©terek

-------------------------------------------------
3. Tokenek: A sz√∂veg feldarabol√°sa
-------------------------------------------------
C√©l:
- A token fogalma √©s jelent≈ës√©ge

Mit jelent a token?
- A sz√∂veget ‚Äûtokenekre‚Äù (r√©sz-szavakra) bontj√°k
- A modell ezek sz√°m√©rt√©k√©vel dolgozik
- A tokeniz√°l√°s befoly√°solja a k√∂lts√©get √©s a feldolgozhat√≥ sz√∂veg hossz√°t

Interakt√≠v p√©lda:
import tiktoken
szoveg = "Hell√≥, vil√°g! Hogy vagy ma? üòä"
encoding = tiktoken.encoding_for_model("gpt-4")
tokenek = encoding.encode(szoveg)
print(f"Eredeti sz√∂veg: {szoveg}")
print(f"Tokenek sz√°ma: {len(tokenek)}")
print(f"Tokenek: {tokenek}")
for i, token in enumerate(tokenek):
    print(f"Token {i}: {token} -> '{encoding.decode([token])}'")

Gyakorlati k√∂vetkezm√©nyek:
- Tokenek alapj√°n t√∂rt√©nik a sz√°ml√°z√°s
- Minden modellnek van maxim√°lis token-hat√°ra
- Egyes szavak t√∂bb tokenb≈ël √°llhatnak

Hasznos eszk√∂z:
- OpenAI Tokenizer: https://platform.openai.com/tokenizer

-------------------------------------------------
4. A k√∂vetkez≈ë token megj√≥sl√°s√°nak var√°zsa
-------------------------------------------------
C√©l:
- Meg√©rteni a tokenenk√©nti el≈ërejelz√©s l√©nyeg√©t

F≈ë elv:
Az LLM minden egyes tokenn√©l val√≥sz√≠n≈±s√©gi eloszl√°sb√≥l v√°laszt.

P√©lda vizualiz√°ci√≥:
import matplotlib.pyplot as plt
kov_token_probak = {"P√°rizs": 0.85, "Lyon": 0.05, "tal√°lhat√≥": 0.03, "nevezik": 0.02, "ismeretlen": 0.01, "egy√©b": 0.04}
plt.bar(kov_token_probak.keys(), kov_token_probak.values())
plt.title("Val√≥sz√≠n≈±s√©gek a k√∂vetkez≈ë tokenre: 'Franciaorsz√°g f≈ëv√°rosa ...'")
plt.ylabel("Val√≥sz√≠n≈±s√©g")
plt.show()

Temperature p√©lda:
def teszt_temperature(client):
    prompt = "√çrj egy kreat√≠v t√∂rt√©netet egy robotr√≥l!"
    for temp in [0.1, 0.7, 1.2]:
        print(f"--- H≈ëm√©rs√©klet {temp} ---")
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                max_tokens=100
            )
            print(response.choices[0].message.content)
        except Exception as e:
            print(f"API hiba: {e}")
# teszt_temperature(client)

- Alacsony temperature: kisz√°m√≠that√≥, ism√©tl≈ëd≈ë kimenet
- Magas temperature: kreat√≠vabb, de n√©ha √©rtelmetlen

-------------------------------------------------
5. Prompt engineering: Hat√©kony utas√≠t√°sok
-------------------------------------------------
C√©l:
- J√≥ promptokat √≠rni, elker√ºlni a tipikus hib√°kat

Mi√©rt fontos?
- A modell pontosan a promptot k√∂veti
- Pontatlan prompt = irrelev√°ns vagy hib√°s eredm√©ny

P√©lda (rossz/j√≥/legjobb):
promtok = [
    "√çrj k√≥dot",  # Rossz
    "√çrj egy Python f√ºggv√©nyt, amely kisz√°molja egy sz√°m faktori√°lis√°t",  # Jobb
    "√çrj egy Python f√ºggv√©nyt, amely:
 1. Pozit√≠v eg√©sz sz√°m faktori√°lis√°t sz√°molja
 2. Hibakezel√©st tartalmaz
 3. Dokument√°lt p√©ld√°kkal
 4. Rekurz√≠v"  # Legjobb
]
for i, prompt in enumerate(promtok):
    print(f"
--- Prompt {i+1} ---")
    print(prompt)
    # Itt lehet h√≠vni az LLM-et √©s ki√≠rni az eredm√©nyt

Halad√≥ technik√°k:
- Few-shot (p√©ld√°k a promptban)
- Chain of thought (‚ÄûGondolkodj l√©p√©sr≈ël l√©p√©sre‚Äù)
- Szerepalap√∫ prompt: ‚ÄûPython tan√°r vagy, magyar√°zd el ...‚Äù

Biztons√°g:
- Vigy√°zat a prompt injection-nel (rosszindulat√∫ bemenetek!)

-------------------------------------------------
6. Kontextusablak: A modell ‚Äûmem√≥ri√°ja‚Äù
-------------------------------------------------
C√©l:
- Meg√©rteni a kontextus fogalm√°t √©s a token limitet

Mit jelent a kontextus?
- A modell csak a legut√≥bbi X tokent l√°tja
- Ha a besz√©lget√©s t√∫l hossz√∫, a legr√©gebbi r√©szek ‚Äûlemaradnak‚Äù

K√≥d p√©lda:
beszelgetes = []
promtok = [
    "A nevem Anna, √©s Pythont tanulok.",
    "Milyen programnyelvet tanulok?",
    "Mi a nevem?",
    "√çrj nekem egy Python hello world-√∂t!"
]
for prompt in promtok:
    beszelgetes.append({"role": "user", "content": prompt})
    response = client.chat.completions.create(
        model="gpt-4",
        messages=beszelgetes
    )
    assistant_msg = response.choices[0].message.content
    beszelgetes.append({"role": "assistant", "content": assistant_msg})
    print(f"
User: {prompt}")
    print(f"Assistant: {assistant_msg}")
    print(f"Jelenlegi besz√©lget√©s hossza: {len(beszelgetes)} √ºzenet")

L√©nyeg:
- Figyelj√ºnk a tokenhaszn√°latra!
- Hosszabb besz√©lget√©s eset√©n √©rdemes √∂sszefoglalni/r√∂vid√≠teni a r√©gebbi r√©szeket.

-------------------------------------------------
7. Param√©terek, amelyek befoly√°solj√°k a m≈±k√∂d√©st
-------------------------------------------------
C√©l:
- A param√©terek k√≠s√©rletez√©se, hat√°suk bemutat√°sa

F≈ë param√©terek:
temperature - V√©letlenszer≈±s√©g (0=determin√°lt, 1=‚Äûsz√≠nesebb‚Äù)
top_p       - Nukleusz minta, diverzit√°s
max_tokens  - Maxim√°lis v√°lasz hossza
frequency_penalty - Ism√©tl√©sek elker√ºl√©se
presence_penalty  - √öj t√©m√°k b√°tor√≠t√°sa

K√≠s√©rlet:
def teszt_parameterek(client):
    alap_prompt = "Magyar√°zd el a g√©pi tanul√°st egyszer≈±en!"
    konfiguraciok = [
        {"temperature": 0, "max_tokens": 50, "name": "Determin√°lt & r√∂vid"},
        {"temperature": 1.0, "max_tokens": 200, "name": "Kreat√≠v & hossz√∫"},
        {"temperature": 0.5, "top_p": 0.9, "name": "Kiegyens√∫lyozott"}
    ]
    for config in konfiguraciok:
        print(f"
--- {config['name']} ---")
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": alap_prompt}],
                **{k: v for k, v in config.items() if k != 'name'}
            )
            print(response.choices[0].message.content)
        except Exception as e:
            print(f"API hiba: {e}")
# teszt_parameterek(client)

-------------------------------------------------
8. Modellv√°ltozatok √∂sszehasonl√≠t√°sa
-------------------------------------------------
C√©l:
- Megfelel≈ë modell kiv√°laszt√°sa

√ñsszehasonl√≠t√≥ t√°bl√°zat:
Modell          | Tud√°s/sz√≠nvonal | K√∂lts√©g | Sebess√©g | Kontextus m√©ret
gpt-3.5-turbo   | J√≥/olcs√≥/gyors  | Alacsony| Gyors    | 16-32k token
gpt-4           | Legjobb/legdr√°g√°bb| Magas  | Lass√∫    | 8k-128k token

P√©lda:
modelek = ["gpt-35-turbo", "gpt-4"]
feladat = "Elemezd ezt a k√≥dot hib√°k szempontj√°b√≥l: for i in range(10): print(i)"
for modell in modelek:
    print(f"
--- {modell} elemz√©s ---")
    # API h√≠v√°s √©s eredm√©ny

-------------------------------------------------
9. Funkci√≥h√≠v√°s: Interakt√≠v LLM-ek
-------------------------------------------------
C√©l:
- Hogyan tud az LLM k√ºls≈ë funkci√≥kat megh√≠vni?

Elv:
- Az LLM struktur√°lt v√°laszt ad (pl. JSON), √≠gy ak√°r k√ºls≈ë API-t is megh√≠vhatunk.

P√©lda:
import json
def idojaras(varos):
    adat = {
        "Budapest": "Napos, 25¬∞C",
        "London": "Es≈ës, 18¬∞C",
        "New York": "Felh≈ës, 22¬∞C"
    }
    return adat.get(varos, "Nincs adat")
funkciok = [{
    "name": "idojaras",
    "description": "Id≈ëj√°r√°s lek√©rdez√©se v√°ros alapj√°n",
    "parameters": {
        "type": "object",
        "properties": {
            "varos": {"type": "string", "description": "V√°ros neve"}
        },
        "required": ["varos"]
    }
}]
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Milyen az id≈ë Budapesten?"}],
    functions=funkciok,
    function_call="auto"
)
if response.choices[0].message.function_call:
    nev = response.choices[0].message.function_call.name
    args = json.loads(response.choices[0].message.function_call.arguments)
    if nev == "idojaras":
        print(f"Eredm√©ny: {idojaras(args['varos'])}")

-------------------------------------------------
10. Be√°gyaz√°sok: Szemantikus hasonl√≥s√°g
-------------------------------------------------
C√©l:
- Szemantikus keres√©s, sz√∂vegek √∂sszehasonl√≠t√°sa

Mi az embedding?
- Sz√∂veget sz√°mvektorokk√° alak√≠tjuk, √≠gy hasonl√≥s√°g m√©rhet≈ë

P√©lda:
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
def get_embedding(text):
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=text
    )
    return response.data[0].embedding
szovegek = [
    "A macska √ºl a sz≈ënyegen.",
    "Egy cica pihen a padl√≥n.",
    "Szeretek Pythont programozni.",
    "A Python a kedvenc nyelvem."
]
emb = [get_embedding(t) for t in szovegek]
sim = cosine_similarity(emb)
for i, a in enumerate(szovegek):
    for j, b in enumerate(szovegek):
        if i < j:
            print(f"'{a}' vs '{b}': {sim[i][j]:.3f}")

-------------------------------------------------
11. Bevezet√©s a RAG-hez (Retrieval-Augmented Generation)
-------------------------------------------------
C√©l:
- A RAG (lek√©rdez√©s-alap√∫ gener√°l√°s) m≈±k√∂d√©s√©nek bemutat√°sa

Mi√©rt kell RAG?
- Az LLM-ek tud√°sa korl√°tos (adott id≈ëpontig tan√≠tott√°k ≈ëket)
- RAG: friss vagy c√©ges adatok becsatol√°sa a gener√°l√°shoz

RAG elv:
1. Lek√©rdez√©s (relev√°ns dokumentumok keres√©se)
2. Kontextus b≈ëv√≠t√©se (a legjobb tal√°latok beilleszt√©se a promptba)
3. V√°laszgener√°l√°s

Egyszer≈± p√©lda:
dokumentumok = [
    "Azure OpenAI Service REST API el√©r√©st ad a nyelvi modellekhez.",
    "Embedding: sz√∂vegek numerikus vektorokk√° alak√≠t√°sa.",
    "A RAG √∂tv√∂zi a keres√©st √©s a gener√°l√°st.",
    "A funkci√≥h√≠v√°s lehet≈ëv√© teszi API-k haszn√°lat√°t."
]
def simple_rag(query, docs, top_k=2):
    query_emb = get_embedding(query)
    sim_list = []
    for doc in docs:
        doc_emb = get_embedding(doc)
        similarity = cosine_similarity([query_emb], [doc_emb])[0][0]
        sim_list.append((doc, similarity))
    sim_list.sort(key=lambda x: x[1], reverse=True)
    relevans = [doc for doc, _ in sim_list[:top_k]]
    context = "\n".join(relevans)
    prompt = f"""Az al√°bbi inform√°ci√≥k alapj√°n:\n{context}\nK√©rd√©s: {query}\nV√°lasz:"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content, relevans

kerdes = "Mi az Azure OpenAI Service?"
valasz, forrasok = simple_rag(kerdes, dokumentumok)
print(f"K√©rd√©s: {kerdes}\nForr√°sok: {forrasok}\nV√°lasz: {valasz}")

-------------------------------------------------
12. Halad√≥ RAG koncepci√≥k
-------------------------------------------------
C√©l:
- Dokumentum darabol√°s (chunking), vektor-adatb√°zis, metaadat sz≈±r√©s

Chunking:
- Hossz√∫ dokumentumokat kis √°tfed≈ë szakaszokra kell bontani

Vektor-adatb√°zis:
- Embeddingek hat√©kony t√°rol√°sa, gyors keres√©s (pl. Azure Cognitive Search, Pinecone, Weaviate)

Halad√≥ p√©lda:
class HaladoRAG:
    def __init__(self):
        self.docs = [
            {"text": "Azure √°rak...", "kategoria": "ar", "datum": "2024-01-15"},
            {"text": "Azure technikai dokument√°ci√≥...", "kategoria": "technikai", "datum": "2024-02-01"},
        ]
    def lekerdezes_szurovel(self, query, kat=None):
        if kat:
            szurt = [d for d in self.docs if d["kategoria"] == kat]
        else:
            szurt = self.docs
        return szurt

rag = HaladoRAG()
print(rag.lekerdezes_szurovel("Mi az Azure √°ra?", kat="ar"))

-------------------------------------------------
13. Val√≥ √©letbeli alkalmaz√°sok √©s legjobb gyakorlatok
-------------------------------------------------
Leggyakoribb felhaszn√°l√°s:
- Dokumentum alap√∫ k√©rd√©s-v√°lasz rendszerek
- K√≥dasszisztensek, fejleszt≈ëi chatbotok
- √úgyf√©lszolg√°lati botok
- Tartalomgener√°l√°s

Legjobb gyakorlatok:
- Hibakezel√©s, API limit figyel√©s, cache-el√©s, napl√≥z√°s, biztons√°g (API-kulcsok v√©delme)
- Etikus haszn√°lat, adatok v√©delme, torz√≠t√°sok elker√ºl√©se

-------------------------------------------------
14. Hibakeres√©s √©s probl√©mamegold√°s
-------------------------------------------------
Gyakori hib√°k:
- Token limit t√∫ll√©p√©s -> Kontextus r√∂vid√≠t√©se
- Gyenge keres√©s -> chunking, embedding jav√≠t√°sa
- Lass√∫ v√°lasz -> kisebb kontextus, cache haszn√°lat
- Irrelev√°ns v√°lasz -> prompt jav√≠t√°sa, sz≈±r√©s

Hibakeres≈ë k√≥d:
def debug_rag_valasz(kerdes, talalatok, valasz):
    print("=== RAG debug ===")
    print(f"K√©rd√©s: {kerdes}")
    print(f"Dokumentumok: {len(talalatok)} db")
    for i, d in enumerate(talalatok):
        print(f"Doc {i+1}: {d[:100]}...")
    print(f"V√°lasz hossza: {len(valasz)} karakter")
    print("=================")

-------------------------------------------------
15. J√∂v≈ëbeli ir√°nyok √©s fejlett t√©m√°k
-------------------------------------------------
- Multimod√°lis LLM-ek (sz√∂veg+k√©pek)
- √úgyn√∂k√∂k, automatiz√°lt eszk√∂zhaszn√°lat
- Finomhangol√°s c√©ges/adott szakter√ºleti adatokon

-------------------------------------------------
16. Gyakorl√≥ feladatok
-------------------------------------------------
1. Saj√°t chatbot fejleszt√©se (FAQ alapj√°n)
2. Dokumentum alap√∫ Q&A rendszer (RAG)
3. K√≥dellen≈ërz≈ë asszisztens (k√≥dmin≈ës√©g)
4. RAG teljes√≠tm√©ny optimaliz√°l√°s (sebess√©g, pontoss√°g)

-------------------------------------------------
17. Tov√°bbi forr√°sok
-------------------------------------------------
- Azure OpenAI dokument√°ci√≥: https://learn.microsoft.com/hu-hu/azure/cognitive-services/openai/
- OpenAI Cookbook: https://cookbook.openai.com/
- LangChain keretrendszer: https://python.langchain.com/
- Vektor-adatb√°zisok: https://www.pinecone.io/, https://weaviate.io/
- √územbehelyez√©si √∫tmutat√≥k: https://learn.microsoft.com/hu-hu/azure/architecture/example-scenario/ai/openai-embeddings

-------------------------------------------------
18. Fogalomt√°r
-------------------------------------------------
- Token: Sz√∂veg legkisebb egys√©ge, amit az LLM √©rtelmez
- Be√°gyaz√°s (embedding): Sz√∂veg numerikus vektor reprezent√°ci√≥ja
- RAG: Retrieval-Augmented Generation (lek√©rdez√©s-alap√∫ gener√°l√°s)
- Kontextusablak: Maxim√°lisan feldolgozhat√≥ sz√∂veghossz (tokenben)
- Temperature: V√©letlenszer≈±s√©g a kimenetben
- Prompt engineering: Hat√©kony utas√≠t√°s √≠r√°sa az LLM sz√°m√°ra
